<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Hyeonho OH | AI Researcher</title>
  <style>
    body {
      font-family: 'Helvetica Neue', sans-serif;
      margin: 0;
      padding: 0;
      color: #2c3e50;
      background: #f4f6f9;
      line-height: 1.6;
    }
        header {
      text-align: center;
      padding: 70px 20px 50px 20px; 
      background: linear-gradient(120deg, #0a3d62, #3c6382);
      color: white;
    }
    header img {
      width: 140px; 
      height: 140px;
      border-radius: 50%;
      border: 4px solid white;
      margin-bottom: 20px;
    }

    section {
      max-width: 850px; 
      margin: 40px auto;
      padding: 20px 30px;
      background: white; 
      border-radius: 12px; 
      box-shadow: 0 4px 12px rgba(0,0,0,0.08);
    }
    section h2 {
      border-bottom: 2px solid #dcdde1;
      padding-bottom: 8px; 
      margin-bottom: 20px;
      font-weight: 600;
      font-size: 1.4em;
    }

    
    .links a {
      display: inline-block;
      margin: 8px 12px;
      padding: 10px 20px;
      text-decoration: none;
      background: #0a3d62; 
      color: white;
      border-radius: 25px; 
      font-size: 0.95em;
      transition: background 0.3s, transform 0.2s; 
    }
    .links a:hover {
      background: #1e6091;
      transform: translateY(-2px); 
    }

    /* ✅ [변경] 푸터: 흰색 → 다크 블루 */
    footer {
      text-align: center;
      background: #0a3d62;
      color: white;
      padding: 20px;
      margin-top: 50px;
      font-size: 0.9em;
    }
  </style>
</head>
<body>
  <header>
    <img src="hyeonhoo_photo.jpeg" alt="Profile Photo">
    <h1>Hyeonho Oh</h1>
    <p>AI Researcher | Computer Vision | Robotics</p>
  </header>

  <section id="about">
    <h2>About Me</h2>
    <p>
      Hi there! I am a master student in Computer Science at the University of Southern Califorina. I received my B.Eng. degree in Department of AI & Software from Gachon University, Korea in 2025.
    </p>
  </section>

  <section id="interests">
    <h2>Research Interests</h2>
    <ul>
      <li>Vision-Language Models</li>
      <li>Visual Understanding</li>
      <li>Application of Visual Information to Hardware System</li>
    </ul>
  </section>
  
<section id="research" style="font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; line-height: 1.6; color: #333; max-width: 900px; margin: auto;">
  <h2 style="border-bottom: 2px solid #444; padding-bottom: 10px; color: #222;">Research Experience</h2>

  <div style="margin-bottom: 25px;">
    <div style="display: flex; justify-content: space-between; align-items: baseline;">
      <strong style="font-size: 1.1em;">Graduate Research Assistant</strong>
      <span style="color: #666; font-size: 0.9em;">Sep 2025 – Present</span>
    </div>
    <div style="margin-top: 4px;">
      <span style="color: #990000; font-weight: bold;">University of Southern California (GLAMOR Lab)</span><br>
      <small style="color: #555;">Advisor: Prof. Jesse Thomason</small>
      <ul style="margin-top: 8px; padding-left: 20px;">
        <li>Advancing robots’ perception, reasoning, and control capabilities by developing a <b>simulation testing suite</b> to evaluate robot learning policies.</li>
      </ul>
    </div>
  </div>

  <div style="margin-bottom: 25px;">
    <div style="display: flex; justify-content: space-between; align-items: baseline;">
      <strong style="font-size: 1.1em;">Graduate Research Assistant</strong>
      <span style="color: #666; font-size: 0.9em;">Sep 2025 – Present</span>
    </div>
    <div style="margin-top: 4px;">
      <span style="color: #990000; font-weight: bold;">University of Southern California (Lira Lab)</span>
      <ul style="margin-top: 8px; padding-left: 20px;">
        <li>Developing a robust <b>Vision-Language-Action (VLA) model</b> for <b>imitation learning</b> designed to adapt to diverse and unstructured environments.</li>
        <li>Researching algorithms for safe, efficient human-robot interaction and multi-agent systems.</li>
      </ul>
    </div>
  </div>

  <div style="margin-bottom: 25px;">
    <div style="display: flex; justify-content: space-between; align-items: baseline;">
      <strong style="font-size: 1.1em;">Research Intern</strong>
      <span style="color: #666; font-size: 0.9em;">Mar 2024 – Aug 2024</span>
    </div>
    <div style="margin-top: 4px;">
      <strong>Electronics and Telecommunications Research Institute (ETRI)</strong><br>
      <small style="color: #555;">Visual Intelligence Research Section (Advisor: Dr. Hyung-Il Kim)</small>
      <ul style="margin-top: 8px; padding-left: 20px;">
        <li>Led a project focused on <b>banner detection and text recognition</b> affected by distortion, occlusion, and noise.</li>
        <li>Analyzed large-scale data (AI-Hub, ICDAR, MJ, ST, Kobert, IIIT5K) and identified accuracy drops in multilingual training.</li>
        <li>Developed a banner detection model utilizing <b>TextBPN</b> and <b>CRAFT</b> with a custom English-Korean bilingual dataset.</li>
        <li>Constructed a contrastive learning structure and applied <b>CLIP</b> models with prompt tuning for text inference and correction.</li>
        <li>Contributed to <b>IEIE</b> paper publications and poster presentations; currently engaged in follow-up research.</li>
      </ul>
      <div style="margin-top: 8px; margin-left: 20px;">
        <a href="https://github.com/LeeHakHo/ETRI_Project" style="text-decoration: none; color: #0366d6; font-size: 0.9em; margin-right: 15px; display: inline-flex; align-items: center;">
          <svg style="width:16px; height:16px; margin-right: 5px;" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path></svg>
          Banner Detection
        </a>
        <a href="https://github.com/LeeHakHo/clipstr" style="text-decoration: none; color: #0366d6; font-size: 0.9em; display: inline-flex; align-items: center;">
          <svg style="width:16px; height:16px; margin-right: 5px;" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path></svg>
          CLIPSTR
        </a>
      </div>
    </div>
  </div>

  <div style="margin-bottom: 25px;">
    <div style="display: flex; justify-content: space-between; align-items: baseline;">
      <strong style="font-size: 1.1em;">Undergraduate Research Assistant</strong>
      <span style="color: #666; font-size: 0.9em;">Previous Period</span>
    </div>
    <div style="margin-top: 4px;">
      <strong>Visual AI Lab at Gachon University</strong><br>
      <small style="color: #555;">Advisor: Prof. Jungchan Cho</small>
      <ul style="margin-top: 8px; padding-left: 20px;">
        <li>Analyzed human states and detailed behaviors in videos for comprehensive situational understanding.</li>
        <li>Developed <b>Video Swin Transformer</b> models to classify human behavior using the VIRAT dataset.</li>
        <li>Implemented ResNet and Transformer-based models using <b>PyTorch</b> and <b>OpenCV</b>; analyzed results with <b>Grad-CAM</b> and <b>W&B</b>.</li>
      </ul>
    </div>
  </div>

  <h2 style="border-bottom: 2px solid #444; padding-bottom: 10px; color: #222; margin-top: 40px;">Project Experience</h2>

  <div style="margin-bottom: 20px;">
    <strong>NICE Challenge, CVPR 2023</strong>
    <ul style="margin-top: 8px; padding-left: 20px;">
      <li>Enhanced OFA and mPLUG zero-shot captioning models, improving accuracy on COCO, Flickr30k, CC3M, and LAION.</li>
      <li>Refined predictions using prompt learning and secondary model feedback loops to guide <b>CLIP</b> word identification.</li>
    </ul>
  </div>

  <div style="margin-bottom: 20px;">
    <strong>Korean Text Recognition Challenge (MSIT)</strong>
    <ul style="margin-top: 8px; padding-left: 20px;">
      <li>Improved <b>TRBA</b> model generalization by upgrading the feature extractor with <b>SENet-based</b> architecture.</li>
      <li>Applied character frequency sampling and ensemble methods; used Grad-CAM to fine-tune weak character recognition.</li>
      <a href="https://github.com/LeeHakHo/TSBA" style="text-decoration: none; color: #0366d6; font-size: 0.9em; display: inline-flex; align-items: center; margin-top: 5px;">
        <svg style="width:16px; height:16px; margin-right: 5px;" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path></svg>
        TSBA
      </a>
    </ul>
  </div>

  <div style="margin-bottom: 20px;">
    <strong>Worldcup Match Prediction Algorithm</strong>
    <ul style="margin-top: 8px; padding-left: 20px;">
      <li>Developed ML algorithms to predict match outcomes using player stats and match records (Predicted Argentina's win).</li>
      <li>Visualized data correlation using Matplotlib and correlation maps.</li>
      <a href="https://github.com/LeeHakHo/WorldcupPrediction" style="text-decoration: none; color: #0366d6; font-size: 0.9em; display: inline-flex; align-items: center; margin-top: 5px;">
        <svg style="width:16px; height:16px; margin-right: 5px;" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path></svg>
        Worldcup Prediction
      </a>
    </ul>
  </div>

  <div style="margin-bottom: 20px;">
    <strong>Object Detection & Human-Object Interaction (Graduation Project)</strong>
    <ul style="margin-top: 8px; padding-left: 20px;">
      <li>Built a system for real-time interaction detection using <b>YOLOv5</b>, <b>FairMOT</b>, and <b>HOTR</b> (Transformer).</li>
      <li>Created a custom custom-interaction dataset and implemented a server/client architecture.</li>
    </ul>
  </div>
</section>
  
<section id="publications">
    <h2>Selected Publications</h2>
    <ul>
        <li>Oh, H.H., Yun, J.S., Bae, Y.S., & Kim, H.I. "<a href="https://drive.google.com/file/d/1x9T30t-aZ0LIQBByVvGI1xP9pWmagzGE/view?usp=drive_link" target="_blank">Investigating Performance of Text Classification Learned with Multi-language for Scene Text Recognition </a>." <i>In Proceedings of the IEIE Summer Conference</i>, pp. 1058-1061, Jun. 2023.</li>
    </ul>
</section>
  
  <section id="Awards">
    <h2>Awards</h2>
    <ul>
      <li><b>Outstanding Talent Award</b> issued by Gachon university</li>
      <li><b>Second Place of Korean Characters OCR AI Contest</b> issued by Korean Ministry of Science and ICT </li>
      <li><b>First Place, Academic Oral Presentation with Data Science</b> issued by Gachon University</li>
    
    
    </ul>
  </section>
  
  <section id="links">
    <h2>Links</h2>
    <div class="links">
      <a href= "https://leehakho.notion.site/Paper-Review-5390717b42774e9b9ba3d06196903019" target="_blank">Paper Record</a>
      <a href="https://github.com/LeeHakHo" target="_blank">GitHub</a>
      <a href="https://www.linkedin.com/in/hyeonhoo" target="_blank">LinkedIn</a>
      <a href="mailto:xyeonxo@gmail.com">Email</a>
    </div>
  </section>

  <footer>
    <p>© 2025 Hyeonho Oh</p>
  </footer>
</body>
</html>
